# Mosaic Match Test

This directory contains test implementations for the Mosaic Match feature, which uses AI-driven trait analysis and vector embeddings to match users with similar personality traits. These testing files serve as a development and debugging environment before integrating with the Nakama backend.

## Overview

The Mosaic Match Test provides a UI to:

1. Extract user traits from chat data
2. Generate embeddings using Vertex AI
3. Store embeddings in Pinecone
4. Find similar users based on trait similarity

This implementation connects to the production API endpoints that will ultimately be called by our Nakama backend.

## Files and Structure

- **page.tsx** - UI for testing the trait extraction and embedding pipeline
- **embedding-api-client.ts** - Client for making API calls to the embedding endpoints

## API Endpoints Used

The test implementation calls these two main endpoints:

1. **Process and Store Embedding**
   - **Endpoint**: `/api/mosaic-match/generate_match_embeddings`
   - **Function**: Extracts traits from user chats, generates embeddings, and stores them in Pinecone
   - **Triggered by**: "Process and Store Embedding" button

2. **Find Similar Users**
   - **Endpoint**: `/api/mosaic-match/pinecone/user/[userId]/similar`
   - **Function**: Finds users with similar trait embeddings based on vector similarity
   - **Triggered by**: "Find Similar Users" button

## Embedding System Details

### Trait Extraction

Traits are extracted from user chat data by:
1. Fetching chat files from S3 using the user's owned file hashes
2. Extracting personality traits from personality-insights.json files
3. Combining traits from multiple chats into a unified set

### Embedding Generation

Embeddings are generated by:
1. Converting trait text into a single text string
2. Sending this text to Vertex AI's text-embedding model (`text-embedding-large-exp-03-07`)
3. Receiving a high-dimensional vector (3072 dimensions) representing the user's traits

> **IMPORTANT**: The dimension size (3072) and model ID (`text-embedding-large-exp-03-07`) are critical for compatibility when transferring this system to the production backend. The test implementation uses these specific values, and any backend integration must match them exactly to ensure vector compatibility in Pinecone.

### Vector Storage

User embeddings are stored in Pinecone with:
1. User ID as the vector ID
2. Embedding vector as the values
3. Metadata including matching status (seeking_match_status) and timestamps

### Matching Status

User matching status is stored in Pinecone metadata with:
- `seeking_match_status` - Whether user is actively seeking matches
- `opt_in_timestamp` - When user opted in
- `last_matched_cycle_id` - Last matching cycle
- `current_match_partner_id` - Current match partner
- `missed_cycles_count` - Count of missed cycles
- `last_opt_out_timestamp` - When user last opted out
- `updatedAt` - Last update timestamp

### Finding Similar Users

Similar users are found by:
1. Retrieving the user's embedding from Pinecone
2. Performing a vector similarity search
3. Filtering for users with `seeking_match_status: true`
4. Returning users sorted by similarity score

## Integration with Nakama

This test implementation previews the functionality that will be called by our Nakama backend. The same API endpoints will be used by Nakama to:

1. Process user traits and generate embeddings
2. Find potential matches based on similarity
3. Track matching status and history

The embedding pipeline can be triggered by Nakama RPCs to refresh embeddings, find matches, and update matching status.

### Critical Integration Notes

When integrating with the Nakama backend, ensure these critical aspects match exactly:

1. **Vector Dimensions**: The test implementation uses 3072-dimensional vectors from Vertex AI. If the Nakama backend is currently using 768 dimensions, this **must be updated** to match the 3072 dimensions used here, or vectors will be incompatible in Pinecone.

2. **Model ID**: The test implementation uses `text-embedding-large-exp-03-07`. The Nakama backend must use the same model to ensure consistent embedding generation.

3. **Pinecone Configuration**: Ensure the Pinecone index is configured for 3072-dimensional vectors, as this is required for the vectors generated by the model used in this implementation.

## Debug Mode

The test implementation includes a debug mode toggle that:
- Enables detailed console logging
- Shows additional information about the embedding process
- Helps diagnose issues in the trait extraction and embedding pipeline

## Implementation Notes

- The trait extraction process batches requests to improve performance
- Rate limiting is implemented for Vertex AI calls to avoid quota issues
- The embedding dimension is fixed at 768 to match the Vertex AI model
- The test implementation uses the same production services that will be used by Nakama